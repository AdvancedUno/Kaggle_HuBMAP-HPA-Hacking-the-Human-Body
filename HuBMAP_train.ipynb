{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":244792,"status":"ok","timestamp":1661387348251,"user":{"displayName":"qwe qwe","userId":"08905623062927154995"},"user_tz":-540},"id":"U8b6QMRAg_4B","outputId":"3cd6aec1-3d55-41b8-b050-72c8851ee275"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n","Collecting torch==1.12.0\n","  Downloading https://download.pytorch.org/whl/cu113/torch-1.12.0%2Bcu113-cp37-cp37m-linux_x86_64.whl (1837.7 MB)\n","\u001b[K     |██████████████▌                 | 834.1 MB 1.2 MB/s eta 0:13:54tcmalloc: large alloc 1147494400 bytes == 0x38c3c000 @  0x7f47e73bc615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |██████████████████▍             | 1055.7 MB 1.4 MB/s eta 0:09:32tcmalloc: large alloc 1434370048 bytes == 0x7d292000 @  0x7f47e73bc615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |███████████████████████▎        | 1336.2 MB 1.3 MB/s eta 0:06:35tcmalloc: large alloc 1792966656 bytes == 0x20c4000 @  0x7f47e73bc615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |█████████████████████████████▌  | 1691.1 MB 1.2 MB/s eta 0:02:03tcmalloc: large alloc 2241208320 bytes == 0x6ceac000 @  0x7f47e73bc615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████████████████| 1837.6 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 1837662208 bytes == 0xf280e000 @  0x7f47e73bb1e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n","tcmalloc: large alloc 2297077760 bytes == 0x160096000 @  0x7f47e73bc615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n","\u001b[K     |████████████████████████████████| 1837.7 MB 8.3 kB/s \n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.0) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n","Collecting torchvision\n","  Downloading torchvision-0.13.1-cp37-cp37m-manylinux1_x86_64.whl (19.1 MB)\n","\u001b[K     |████████████████████████████████| 19.1 MB 1.2 MB/s \n","\u001b[?25h  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.13.0%2Bcu113-cp37-cp37m-linux_x86_64.whl (23.4 MB)\n","\u001b[K     |████████████████████████████████| 23.4 MB 74.8 MB/s \n","\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n","Installing collected packages: torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.13.1+cu113\n","    Uninstalling torchvision-0.13.1+cu113:\n","      Successfully uninstalled torchvision-0.13.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.12.0+cu113 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.12.0+cu113 which is incompatible.\u001b[0m\n","Successfully installed torch-1.12.0+cu113 torchvision-0.13.0+cu113\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting openmim\n","  Downloading openmim-0.2.1-py2.py3-none-any.whl (49 kB)\n","\u001b[K     |████████████████████████████████| 49 kB 3.9 MB/s \n","\u001b[?25hCollecting model-index\n","  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n","Collecting colorama\n","  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from openmim) (1.3.5)\n","Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.7/dist-packages (from openmim) (21.1.3)\n","Collecting rich\n","  Downloading rich-12.5.1-py3-none-any.whl (235 kB)\n","\u001b[K     |████████████████████████████████| 235 kB 14.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from openmim) (2.23.0)\n","Requirement already satisfied: Click in /usr/local/lib/python3.7/dist-packages (from openmim) (7.1.2)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from openmim) (0.8.10)\n","Requirement already satisfied: markdown in /usr/local/lib/python3.7/dist-packages (from model-index->openmim) (3.4.1)\n","Collecting ordered-set\n","  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from model-index->openmim) (6.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown->model-index->openmim) (4.12.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown->model-index->openmim) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown->model-index->openmim) (3.8.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->openmim) (2022.2.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->openmim) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->openmim) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->openmim) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->openmim) (2022.6.15)\n","Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich->openmim) (2.6.1)\n","Collecting commonmark<0.10.0,>=0.9.0\n","  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 9.2 MB/s \n","\u001b[?25hInstalling collected packages: ordered-set, commonmark, rich, model-index, colorama, openmim\n","Successfully installed colorama-0.4.5 commonmark-0.9.1 model-index-0.1.11 openmim-0.2.1 ordered-set-4.1.0 rich-12.5.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/index.html\n","Collecting mmcv-full==1.6.0\n","  Downloading https://download.openmmlab.com/mmcv/dist/cu113/torch1.12.0/mmcv_full-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (40.1 MB)\n","\u001b[K     |████████████████████████████████| 40.1 MB 11.4 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.6.0) (6.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.6.0) (21.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.6.0) (1.21.6)\n","Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.6.0) (4.6.0.66)\n","Collecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Collecting yapf\n","  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n","\u001b[K     |████████████████████████████████| 190 kB 7.4 MB/s \n","\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full==1.6.0) (7.1.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full==1.6.0) (3.0.9)\n","Installing collected packages: yapf, addict, mmcv-full\n","Successfully installed addict-2.4.0 mmcv-full-1.6.0 yapf-0.32.0\n","Cloning into 'mmsegmentation'...\n","remote: Enumerating objects: 10517, done.\u001b[K\n","remote: Counting objects: 100% (392/392), done.\u001b[K\n","remote: Compressing objects: 100% (231/231), done.\u001b[K\n","remote: Total 10517 (delta 171), reused 320 (delta 151), pack-reused 10125\u001b[K\n","Receiving objects: 100% (10517/10517), 14.61 MiB | 11.17 MiB/s, done.\n","Resolving deltas: 100% (7601/7601), done.\n","/content/mmsegmentation\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Obtaining file:///content/mmsegmentation\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.27.0) (3.2.2)\n","Collecting mmcls>=0.20.1\n","  Downloading mmcls-0.23.2-py2.py3-none-any.whl (578 kB)\n","\u001b[K     |████████████████████████████████| 578 kB 8.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.27.0) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.27.0) (21.3)\n","Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.27.0) (3.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.27.0) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.27.0) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.27.0) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.27.0) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmsegmentation==0.27.0) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mmsegmentation==0.27.0) (1.15.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable->mmsegmentation==0.27.0) (4.12.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->mmsegmentation==0.27.0) (0.2.5)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable->mmsegmentation==0.27.0) (3.8.1)\n","Installing collected packages: mmcls, mmsegmentation\n","  Running setup.py develop for mmsegmentation\n","Successfully installed mmcls-0.23.2 mmsegmentation-0.27.0\n","Setup complete. Using torch 1.12.0+cu113 (Tesla T4)\n","Mounted at /content/drive\n"]}],"source":["!pip install torch==1.12.0 torchvision --extra-index-url https://download.pytorch.org/whl/cu113\n","# Install MMCV\n","!pip install openmim\n","!mim install mmcv-full==1.6.0\n","!git clone https://github.com/open-mmlab/mmsegmentation.git\n","\n","%cd mmsegmentation\n","!pip install -e .\n","\n","import torch\n","print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")\n","\n","from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n","import mmcv\n","import os.path as osp\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["from glob import glob\n","import numpy as np\n","import cv2\n","import os\n","from sklearn.model_selection import StratifiedKFold\n","\n","Fold = 10\n","all_mask_files = glob(\"/content/drive/MyDrive/hubmap-organ-segmentation/masks/*\")\n","masks = []\n","num_mask = np.zeros((6,Fold))\n","\n","!mkdir splits\n","\n","split = list(StratifiedKFold(n_splits=Fold, shuffle=True, random_state=2022).split(all_mask_files, [0]*len(all_mask_files)))\n","for fold, (train_idx, valid_idx) in enumerate(split):\n","    with open(f\"/content/drive/MyDrive/hubmap-organ-segmentation/splits/fold_{fold}.txt\", \"w\") as f:\n","        for idx in train_idx:\n","            f.write(os.path.basename(all_mask_files[idx])[:-4] + \"\\n\")\n","    with open(f\"/content/drive/MyDrive/hubmap-organ-segmentation/splits/valid_{fold}.txt\", \"w\") as f:\n","        for idx in valid_idx:\n","            f.write(os.path.basename(all_mask_files[idx])[:-4] + \"\\n\")"],"metadata":{"id":"puyJzoIFmYKm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%bash\n","\n","cat <<EOT >> ./config.py\n","\n","norm_cfg = dict(type='SyncBN', requires_grad=True)\n","model = dict(\n","    type='EncoderDecoder',\n","    pretrained=None,\n","    backbone=dict(\n","        type='MixVisionTransformer',\n","        in_channels=3,\n","        embed_dims=32,\n","        num_stages=4,\n","        num_layers=[2, 2, 2, 2],\n","        num_heads=[1, 2, 5, 8],\n","        patch_sizes=[7, 3, 3, 3],\n","        sr_ratios=[8, 4, 2, 1],\n","        out_indices=(0, 1, 2, 3),\n","        mlp_ratio=4,\n","        qkv_bias=True,\n","        drop_rate=0.0,\n","        attn_drop_rate=0.0,\n","        drop_path_rate=0.1),\n","    decode_head=dict(\n","        type='SegformerHead',\n","        in_channels=[32, 64, 160, 256],\n","        in_index=[0, 1, 2, 3],\n","        channels=256,\n","        dropout_ratio=0.1,\n","        num_classes=6,\n","        norm_cfg=norm_cfg,\n","        align_corners=False,\n","        loss_decode=dict(\n","            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n","    # model training and testing settings\n","    train_cfg=dict(),\n","    test_cfg=dict(mode='whole'))\n","\n","checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'  # noqa\n","\n","# model settings\n","model = dict(\n","    pretrained = checkpoint,\n","    backbone=dict(\n","        embed_dims=64, num_heads=[1, 2, 5, 8], num_layers=[3, 6, 40, 3]),\n","    decode_head=dict(in_channels=[64, 128, 320, 512], num_classes=6))\n","\n","# dataset settings\n","dataset_type = 'CustomDataset'\n","data_root = '/content/drive/MyDrive/hubmap-organ-segmentation/'\n","classes = ['background', 'kidney', 'prostate', 'largeintestine', 'spleen', 'lung']\n","palette = [[0,0,0], [255,0,0], [0,255,0], [0,0,255], [255,255,0], [255,0,255]]\n","img_norm_cfg = dict(mean=[196.869, 190.186, 194.802], std=[63.010, 66.765, 65.745], to_rgb=True)\n","size = 256\n","\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(type='Resize', img_scale=(size, size), keep_ratio=True),\n","    dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n","    dict(type='Normalize', **img_norm_cfg),\n","    dict(type='Pad', size=(size, size), pad_val=0, seg_pad_val=255),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(size, size),\n","        flip=False,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(type='Normalize', **img_norm_cfg),\n","            dict(type='Pad', size=(size, size), pad_val=0, seg_pad_val=255),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img']),\n","        ])\n","]\n","data = dict(\n","    samples_per_gpu=8,\n","    workers_per_gpu=4,\n","    train=dict(\n","        type=dataset_type,\n","        data_root=data_root,\n","        img_dir='train',\n","        ann_dir='masks',\n","        img_suffix=\".png\",\n","        seg_map_suffix='.png',\n","        split=\"splits/fold_0.txt\",\n","        classes=classes,\n","        palette=palette,\n","        pipeline=train_pipeline),\n","    val=dict(\n","        type=dataset_type,\n","        data_root=data_root,\n","        img_dir='train',\n","        ann_dir='masks',\n","        img_suffix=\".png\",\n","        seg_map_suffix='.png',\n","        split=\"splits/valid_0.txt\",\n","        classes=classes,\n","        palette=palette,\n","        pipeline=test_pipeline),\n","    test=dict(\n","        type=dataset_type,\n","        data_root=data_root,\n","        test_mode=True,\n","        img_dir='train',\n","        ann_dir='masks',\n","        img_suffix=\".png\",\n","        seg_map_suffix='.png',\n","        classes=classes,\n","        palette=palette,\n","        pipeline=test_pipeline))\n","\n","# yapf:disable\n","log_config = dict(\n","    interval=50,\n","    hooks=[\n","        dict(type='TextLoggerHook', by_epoch=False),\n","    ])\n","# yapf:enable\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = None\n","resume_from = None\n","workflow = [('train', 1)]\n","cudnn_benchmark = True\n","\n","total_iters = 5000\n","# optimizer\n","# optimizer = dict(type='AdamW', lr=1e-3, betas=(0.9, 0.999), weight_decay=0.05)\n","optimizer = dict(\n","    _delete_=True,\n","    type='AdamW',\n","    lr=0.00006,\n","    betas=(0.9, 0.999),\n","    weight_decay=0.01,\n","    paramwise_cfg=dict(\n","        custom_keys={\n","            'pos_block': dict(decay_mult=0.),\n","            'norm': dict(decay_mult=0.),\n","            'head': dict(lr_mult=10.)\n","        }))\n","#1 -> \n","# 500 -> 1epoch \n","optimizer_config = dict(type='Fp16OptimizerHook', loss_scale='dynamic')\n","# optimizer_config = dict()\n","# learning policy\n","# lr_config = dict(policy='poly',\n","#                  warmup='linear',\n","#                  warmup_iters=500,\n","#                  warmup_ratio=1e-6,\n","#                  power=1.0, min_lr=0.0, by_epoch=False)\n","lr_config = dict(\n","    _delete_=True,\n","    policy='poly',\n","    warmup='linear',\n","    warmup_iters=1500,\n","    warmup_ratio=1e-6,\n","    power=1.0,\n","    min_lr=0.0,\n","    by_epoch=False)\n","# runtime settings\n","find_unused_parameters = True\n","runner = dict(type = 'IterBasedRunner', max_iters = total_iters)\n","checkpoint_config = dict(by_epoch=False, interval=-1, save_optimizer=False)\n","evaluation = dict(by_epoch=False, interval=500, metric='mDice', pre_eval=True)\n","fp16 = dict()\n","work_dir = './baseline'\n","EOT"],"metadata":{"id":"TrdrfE9dhQsK","executionInfo":{"status":"ok","timestamp":1661388529264,"user_tz":-540,"elapsed":421,"user":{"displayName":"qwe qwe","userId":"08905623062927154995"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["%%bash\n","\n","cat <<EOT >> ./config2.py\n","\n","_base_ = ['/content/mmsegmentation/configs/segformer/segformer_mit-b0_512x512_160k_ade20k.py']\n","\n","# dataset settings\n","dataset_type = 'CustomDataset'\n","data_root = '/content/drive/MyDrive/hubmap-organ-segmentation/'\n","classes = ['background', 'kidney', 'prostate', 'largeintestine', 'spleen', 'lung']\n","palette = [[0,0,0], [255,0,0], [0,255,0], [0,0,255], [255,255,0], [255,0,255]]\n","img_norm_cfg = dict(mean=[196.869, 190.186, 194.802], std=[63.010, 66.765, 65.745], to_rgb=True)\n","size = 256\n","\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(type='Resize', img_scale=(size, size), keep_ratio=True),\n","    dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n","    dict(type='Normalize', **img_norm_cfg),\n","    dict(type='Pad', size=(size, size), pad_val=0, seg_pad_val=255),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(size, size),\n","        flip=False,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(type='Normalize', **img_norm_cfg),\n","            dict(type='Pad', size=(size, size), pad_val=0, seg_pad_val=255),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img']),\n","        ])\n","]\n","data = dict(\n","    samples_per_gpu=8,\n","    workers_per_gpu=4,\n","    train=dict(\n","        type=dataset_type,\n","        data_root=data_root,\n","        img_dir='train',\n","        ann_dir='masks',\n","        img_suffix=\".png\",\n","        seg_map_suffix='.png',\n","        split=\"splits/fold_0.txt\",\n","        classes=classes,\n","        palette=palette,\n","        pipeline=train_pipeline),\n","    val=dict(\n","        type=dataset_type,\n","        data_root=data_root,\n","        img_dir='train',\n","        ann_dir='masks',\n","        img_suffix=\".png\",\n","        seg_map_suffix='.png',\n","        split=\"splits/valid_0.txt\",\n","        classes=classes,\n","        palette=palette,\n","        pipeline=test_pipeline),\n","    test=dict(\n","        type=dataset_type,\n","        data_root=data_root,\n","        test_mode=True,\n","        img_dir='train',\n","        ann_dir='masks',\n","        img_suffix=\".png\",\n","        seg_map_suffix='.png',\n","        classes=classes,\n","        palette=palette,\n","        pipeline=test_pipeline))\n","\n","checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'  # noqa\n","\n","# model settings\n","model = dict(\n","    pretrained=checkpoint,\n","    backbone=dict(\n","        embed_dims=64, num_heads=[1, 2, 5, 8], num_layers=[3, 6, 40, 3]),\n","    decode_head=dict(in_channels=[64, 128, 320, 512]))\n","\n","EOT"],"metadata":{"id":"W2PTK0LUe4n8","executionInfo":{"status":"ok","timestamp":1661389147655,"user_tz":-540,"elapsed":315,"user":{"displayName":"qwe qwe","userId":"08905623062927154995"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["!python ./tools/train.py ./config2.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_MnjUHohli5H","outputId":"3adf02a3-e53b-47ad-a047-1330e4749ce3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-08-25 00:59:13,064 - mmseg - INFO - Multi-processing start method is `None`\n","2022-08-25 00:59:13,064 - mmseg - INFO - OpenCV num_threads is `2\n","2022-08-25 00:59:13,101 - mmseg - INFO - Environment info:\n","------------------------------------------------------------\n","sys.platform: linux\n","Python: 3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\n","CUDA available: True\n","GPU 0: Tesla T4\n","CUDA_HOME: /usr/local/cuda\n","NVCC: Cuda compilation tools, release 11.1, V11.1.105\n","GCC: x86_64-linux-gnu-gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n","PyTorch: 1.12.0+cu113\n","PyTorch compiling details: PyTorch built with:\n","  - GCC 9.3\n","  - C++ Version: 201402\n","  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n","  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)\n","  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n","  - LAPACK is enabled (usually provided by MKL)\n","  - NNPACK is enabled\n","  - CPU capability usage: AVX2\n","  - CUDA Runtime 11.3\n","  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n","  - CuDNN 8.3.2  (built against CUDA 11.5)\n","  - Magma 2.5.2\n","  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n","\n","TorchVision: 0.13.0+cu113\n","OpenCV: 4.6.0\n","MMCV: 1.6.0\n","MMCV Compiler: GCC 9.3\n","MMCV CUDA Compiler: 11.3\n","MMSegmentation: 0.27.0+dd42fa8\n","------------------------------------------------------------\n","\n","2022-08-25 00:59:13,101 - mmseg - INFO - Distributed training: False\n","2022-08-25 00:59:14,243 - mmseg - INFO - Config:\n","norm_cfg = dict(type='SyncBN', requires_grad=True)\n","model = dict(\n","    type='EncoderDecoder',\n","    pretrained=\n","    'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth',\n","    backbone=dict(\n","        type='MixVisionTransformer',\n","        in_channels=3,\n","        embed_dims=64,\n","        num_stages=4,\n","        num_layers=[3, 6, 40, 3],\n","        num_heads=[1, 2, 5, 8],\n","        patch_sizes=[7, 3, 3, 3],\n","        sr_ratios=[8, 4, 2, 1],\n","        out_indices=(0, 1, 2, 3),\n","        mlp_ratio=4,\n","        qkv_bias=True,\n","        drop_rate=0.0,\n","        attn_drop_rate=0.0,\n","        drop_path_rate=0.1),\n","    decode_head=dict(\n","        type='SegformerHead',\n","        in_channels=[64, 128, 320, 512],\n","        in_index=[0, 1, 2, 3],\n","        channels=256,\n","        dropout_ratio=0.1,\n","        num_classes=6,\n","        norm_cfg=dict(type='SyncBN', requires_grad=True),\n","        align_corners=False,\n","        loss_decode=dict(\n","            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n","    train_cfg=dict(),\n","    test_cfg=dict(mode='whole'))\n","log_config = dict(\n","    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = None\n","resume_from = None\n","workflow = [('train', 1)]\n","cudnn_benchmark = True\n","optimizer = dict(\n","    type='AdamW',\n","    lr=6e-05,\n","    betas=(0.9, 0.999),\n","    weight_decay=0.01,\n","    paramwise_cfg=dict(\n","        custom_keys=dict(\n","            pos_block=dict(decay_mult=0.0),\n","            norm=dict(decay_mult=0.0),\n","            head=dict(lr_mult=10.0))))\n","optimizer_config = dict()\n","lr_config = dict(\n","    policy='poly',\n","    warmup='linear',\n","    warmup_iters=1500,\n","    warmup_ratio=1e-06,\n","    power=1.0,\n","    min_lr=0.0,\n","    by_epoch=False)\n","runner = dict(type='IterBasedRunner', max_iters=5000)\n","checkpoint_config = dict(by_epoch=False, interval=5000)\n","evaluation = dict(interval=500, metric='mIoU', pre_eval=True)\n","checkpoint = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'\n","data = dict(\n","    samples_per_gpu=8,\n","    workers_per_gpu=4,\n","    train=dict(\n","        type='CustomDataset',\n","        data_root='/content/drive/MyDrive/hubmap-organ-segmentation/',\n","        img_dir='train',\n","        ann_dir='masks',\n","        img_suffix='.png',\n","        seg_map_suffix='.png',\n","        split='splits/fold_0.txt',\n","        classes=[\n","            'background', 'kidney', 'prostate', 'largeintestine', 'spleen',\n","            'lung'\n","        ],\n","        palette=[[0, 0, 0], [255, 0, 0], [0, 255, 0], [0, 0, 255],\n","                 [255, 255, 0], [255, 0, 255]],\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(type='LoadAnnotations'),\n","            dict(type='Resize', img_scale=(256, 256), keep_ratio=True),\n","            dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n","            dict(\n","                type='Normalize',\n","                mean=[196.869, 190.186, 194.802],\n","                std=[63.01, 66.765, 65.745],\n","                to_rgb=True),\n","            dict(type='Pad', size=(256, 256), pad_val=0, seg_pad_val=255),\n","            dict(type='DefaultFormatBundle'),\n","            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n","        ]),\n","    val=dict(\n","        type='CustomDataset',\n","        data_root='/content/drive/MyDrive/hubmap-organ-segmentation/',\n","        img_dir='train',\n","        ann_dir='masks',\n","        img_suffix='.png',\n","        seg_map_suffix='.png',\n","        split='splits/valid_0.txt',\n","        classes=[\n","            'background', 'kidney', 'prostate', 'largeintestine', 'spleen',\n","            'lung'\n","        ],\n","        palette=[[0, 0, 0], [255, 0, 0], [0, 255, 0], [0, 0, 255],\n","                 [255, 255, 0], [255, 0, 255]],\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(256, 256),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[196.869, 190.186, 194.802],\n","                        std=[63.01, 66.765, 65.745],\n","                        to_rgb=True),\n","                    dict(\n","                        type='Pad',\n","                        size=(256, 256),\n","                        pad_val=0,\n","                        seg_pad_val=255),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ]),\n","    test=dict(\n","        type='CustomDataset',\n","        data_root='/content/drive/MyDrive/hubmap-organ-segmentation/',\n","        test_mode=True,\n","        img_dir='train',\n","        ann_dir='masks',\n","        img_suffix='.png',\n","        seg_map_suffix='.png',\n","        classes=[\n","            'background', 'kidney', 'prostate', 'largeintestine', 'spleen',\n","            'lung'\n","        ],\n","        palette=[[0, 0, 0], [255, 0, 0], [0, 255, 0], [0, 0, 255],\n","                 [255, 255, 0], [255, 0, 255]],\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(256, 256),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[196.869, 190.186, 194.802],\n","                        std=[63.01, 66.765, 65.745],\n","                        to_rgb=True),\n","                    dict(\n","                        type='Pad',\n","                        size=(256, 256),\n","                        pad_val=0,\n","                        seg_pad_val=255),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ]))\n","dataset_type = 'CustomDataset'\n","data_root = '/content/drive/MyDrive/hubmap-organ-segmentation/'\n","classes = [\n","    'background', 'kidney', 'prostate', 'largeintestine', 'spleen', 'lung'\n","]\n","palette = [[0, 0, 0], [255, 0, 0], [0, 255, 0], [0, 0, 255], [255, 255, 0],\n","           [255, 0, 255]]\n","img_norm_cfg = dict(\n","    mean=[196.869, 190.186, 194.802], std=[63.01, 66.765, 65.745], to_rgb=True)\n","size = 256\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations'),\n","    dict(type='Resize', img_scale=(256, 256), keep_ratio=True),\n","    dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n","    dict(\n","        type='Normalize',\n","        mean=[196.869, 190.186, 194.802],\n","        std=[63.01, 66.765, 65.745],\n","        to_rgb=True),\n","    dict(type='Pad', size=(256, 256), pad_val=0, seg_pad_val=255),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(256, 256),\n","        flip=False,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(\n","                type='Normalize',\n","                mean=[196.869, 190.186, 194.802],\n","                std=[63.01, 66.765, 65.745],\n","                to_rgb=True),\n","            dict(type='Pad', size=(256, 256), pad_val=0, seg_pad_val=255),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img'])\n","        ])\n","]\n","work_dir = './work_dirs/config2'\n","gpu_ids = [0]\n","auto_resume = False\n","\n","2022-08-25 00:59:14,243 - mmseg - INFO - Set random seed to 1808836413, deterministic: False\n","/content/mmsegmentation/mmseg/models/backbones/mit.py:365: UserWarning: DeprecationWarning: pretrained is deprecated, please use \"init_cfg\" instead\n","  warnings.warn('DeprecationWarning: pretrained is deprecated, '\n","/content/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:236: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n","  'Default ``avg_non_ignore`` is False, if you would like to '\n","2022-08-25 00:59:15,042 - mmseg - INFO - initialize MixVisionTransformer with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'}\n","2022-08-25 00:59:15,042 - mmcv - INFO - load model from: https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth\n","2022-08-25 00:59:15,043 - mmcv - INFO - load checkpoint from http path: https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth\n","2022-08-25 00:59:15,604 - mmseg - INFO - initialize SegformerHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n","./tools/train.py:207: UserWarning: SyncBN is only supported with DDP. To be compatible with DP, we convert SyncBN to BN. Please use dist_train.sh which can avoid this error.\n","  'SyncBN is only supported with DDP. To be compatible with DP, '\n","2022-08-25 00:59:15,622 - mmseg - INFO - EncoderDecoder(\n","  (backbone): MixVisionTransformer(\n","    (layers): ModuleList(\n","      (0): ModuleList(\n","        (0): PatchEmbed(\n","          (projection): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n","          (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","        )\n","        (1): ModuleList(\n","          (0): TransformerEncoderLayer(\n","            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n","              (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (1): TransformerEncoderLayer(\n","            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n","              (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (2): TransformerEncoderLayer(\n","            (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))\n","              (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","        )\n","        (2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n","      )\n","      (1): ModuleList(\n","        (0): PatchEmbed(\n","          (projection): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","        )\n","        (1): ModuleList(\n","          (0): TransformerEncoderLayer(\n","            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n","              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (1): TransformerEncoderLayer(\n","            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n","              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (2): TransformerEncoderLayer(\n","            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n","              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (3): TransformerEncoderLayer(\n","            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n","              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (4): TransformerEncoderLayer(\n","            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n","              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (5): TransformerEncoderLayer(\n","            (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))\n","              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","        )\n","        (2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n","      )\n","      (2): ModuleList(\n","        (0): PatchEmbed(\n","          (projection): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","          (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","        )\n","        (1): ModuleList(\n","          (0): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (1): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (2): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (3): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (4): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (5): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (6): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (7): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (8): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (9): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (10): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (11): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (12): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (13): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (14): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (15): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (16): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (17): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (18): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (19): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (20): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (21): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (22): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (23): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (24): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (25): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (26): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (27): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (28): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (29): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (30): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (31): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (32): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (33): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (34): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (35): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (36): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (37): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (38): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (39): TransformerEncoderLayer(\n","            (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","              (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n","              (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            )\n","            (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","        )\n","        (2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)\n","      )\n","      (3): ModuleList(\n","        (0): PatchEmbed(\n","          (projection): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","          (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","        )\n","        (1): ModuleList(\n","          (0): TransformerEncoderLayer(\n","            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","            )\n","            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (1): TransformerEncoderLayer(\n","            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","            )\n","            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","          (2): TransformerEncoderLayer(\n","            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","            (attn): EfficientMultiheadAttention(\n","              (attn): MultiheadAttention(\n","                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n","              )\n","              (proj_drop): Dropout(p=0.0, inplace=False)\n","              (dropout_layer): DropPath()\n","            )\n","            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","            (ffn): MixFFN(\n","              (activate): GELU(approximate=none)\n","              (layers): Sequential(\n","                (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n","                (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n","                (2): GELU(approximate=none)\n","                (3): Dropout(p=0.0, inplace=False)\n","                (4): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n","                (5): Dropout(p=0.0, inplace=False)\n","              )\n","              (dropout_layer): DropPath()\n","            )\n","          )\n","        )\n","        (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segformer/mit_b5_20220624-658746d9.pth'}\n","  (decode_head): SegformerHead(\n","    input_transform=multiple_select, ignore_index=255, align_corners=False\n","    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n","    (conv_seg): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n","    (dropout): Dropout2d(p=0.1, inplace=False)\n","    (convs): ModuleList(\n","      (0): ConvModule(\n","        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","      (1): ConvModule(\n","        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","      (2): ConvModule(\n","        (conv): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","      (3): ConvModule(\n","        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (activate): ReLU(inplace=True)\n","      )\n","    )\n","    (fusion_conv): ConvModule(\n","      (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (activate): ReLU(inplace=True)\n","    )\n","  )\n","  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",")\n","2022-08-25 00:59:15,728 - mmseg - INFO - Loaded 2511 images\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","2022-08-25 00:59:19,644 - mmseg - INFO - Loaded 280 images\n","2022-08-25 00:59:19,646 - mmseg - INFO - Start running, host: root@d32579c3ed2f, work_dir: /content/mmsegmentation/work_dirs/config2\n","2022-08-25 00:59:19,646 - mmseg - INFO - Hooks will be executed in the following order:\n","before_run:\n","(VERY_HIGH   ) PolyLrUpdaterHook                  \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_train_epoch:\n","(VERY_HIGH   ) PolyLrUpdaterHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_train_iter:\n","(VERY_HIGH   ) PolyLrUpdaterHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n"," -------------------- \n","after_train_iter:\n","(ABOVE_NORMAL) OptimizerHook                      \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","after_train_epoch:\n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_val_epoch:\n","(LOW         ) IterTimerHook                      \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_epoch:\n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","after_run:\n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","2022-08-25 00:59:19,646 - mmseg - INFO - workflow: [('train', 1)], max: 5000 iters\n","2022-08-25 00:59:19,647 - mmseg - INFO - Checkpoints will be saved to /content/mmsegmentation/work_dirs/config2 by HardDiskBackend.\n","2022-08-25 00:59:58,890 - mmseg - INFO - Iter [50/5000]\tlr: 1.941e-06, eta: 1:04:32, time: 0.782, data_time: 0.099, memory: 4974, decode.loss_ce: 1.7286, decode.acc_seg: 40.0352, loss: 1.7286\n","2022-08-25 01:00:32,899 - mmseg - INFO - Iter [100/5000]\tlr: 3.882e-06, eta: 0:59:42, time: 0.680, data_time: 0.063, memory: 4974, decode.loss_ce: 1.5853, decode.acc_seg: 81.5178, loss: 1.5853\n","2022-08-25 01:01:12,493 - mmseg - INFO - Iter [150/5000]\tlr: 5.782e-06, eta: 1:00:44, time: 0.792, data_time: 0.182, memory: 4974, decode.loss_ce: 1.3133, decode.acc_seg: 91.4390, loss: 1.3133\n","2022-08-25 01:01:48,639 - mmseg - INFO - Iter [200/5000]\tlr: 7.643e-06, eta: 0:59:32, time: 0.723, data_time: 0.116, memory: 4974, decode.loss_ce: 1.0000, decode.acc_seg: 89.6214, loss: 1.0000\n","2022-08-25 01:02:24,057 - mmseg - INFO - Iter [250/5000]\tlr: 9.464e-06, eta: 0:58:21, time: 0.708, data_time: 0.103, memory: 4974, decode.loss_ce: 0.7058, decode.acc_seg: 90.0659, loss: 0.7058\n","2022-08-25 01:02:56,527 - mmseg - INFO - Iter [300/5000]\tlr: 1.124e-05, eta: 0:56:35, time: 0.649, data_time: 0.035, memory: 4974, decode.loss_ce: 0.5076, decode.acc_seg: 90.3039, loss: 0.5076\n","2022-08-25 01:03:29,838 - mmseg - INFO - Iter [350/5000]\tlr: 1.299e-05, eta: 0:55:22, time: 0.666, data_time: 0.055, memory: 4974, decode.loss_ce: 0.3851, decode.acc_seg: 90.8684, loss: 0.3851\n","2022-08-25 01:04:00,503 - mmseg - INFO - Iter [400/5000]\tlr: 1.469e-05, eta: 0:53:48, time: 0.613, data_time: 0.006, memory: 4974, decode.loss_ce: 0.2934, decode.acc_seg: 92.9925, loss: 0.2934\n","2022-08-25 01:04:31,238 - mmseg - INFO - Iter [450/5000]\tlr: 1.635e-05, eta: 0:52:29, time: 0.615, data_time: 0.007, memory: 4974, decode.loss_ce: 0.2685, decode.acc_seg: 92.9051, loss: 0.2685\n","2022-08-25 01:05:01,861 - mmseg - INFO - Iter [500/5000]\tlr: 1.797e-05, eta: 0:51:18, time: 0.612, data_time: 0.006, memory: 4974, decode.loss_ce: 0.2397, decode.acc_seg: 93.4157, loss: 0.2397\n","[>>] 280/280, 2.6 task/s, elapsed: 106s, ETA:     0s2022-08-25 01:06:48,327 - mmseg - INFO - per class results:\n","2022-08-25 01:06:48,328 - mmseg - INFO - \n","+----------------+-------+-------+\n","|     Class      |  IoU  |  Acc  |\n","+----------------+-------+-------+\n","|   background   | 93.68 | 97.62 |\n","|     kidney     |  0.0  |  0.0  |\n","|    prostate    | 62.96 | 87.09 |\n","| largeintestine |  65.9 | 82.24 |\n","|     spleen     |  0.0  |  0.0  |\n","|      lung      |  0.0  |  0.0  |\n","+----------------+-------+-------+\n","2022-08-25 01:06:48,329 - mmseg - INFO - Summary:\n","2022-08-25 01:06:48,329 - mmseg - INFO - \n","+-------+-------+-------+\n","|  aAcc |  mIoU |  mAcc |\n","+-------+-------+-------+\n","| 94.03 | 37.09 | 44.49 |\n","+-------+-------+-------+\n","2022-08-25 01:06:48,330 - mmseg - INFO - Iter(val) [280]\taAcc: 0.9403, mIoU: 0.3709, mAcc: 0.4449, IoU.background: 0.9368, IoU.kidney: 0.0000, IoU.prostate: 0.6296, IoU.largeintestine: 0.6590, IoU.spleen: 0.0000, IoU.lung: 0.0000, Acc.background: 0.9762, Acc.kidney: 0.0000, Acc.prostate: 0.8709, Acc.largeintestine: 0.8224, Acc.spleen: 0.0000, Acc.lung: 0.0000\n","2022-08-25 01:07:19,040 - mmseg - INFO - Iter [550/5000]\tlr: 1.955e-05, eta: 1:04:37, time: 2.744, data_time: 2.136, memory: 9861, decode.loss_ce: 0.2038, decode.acc_seg: 93.9211, loss: 0.2038\n","2022-08-25 01:07:50,524 - mmseg - INFO - Iter [600/5000]\tlr: 2.109e-05, eta: 1:02:25, time: 0.630, data_time: 0.007, memory: 9861, decode.loss_ce: 0.1741, decode.acc_seg: 94.5307, loss: 0.1741\n","2022-08-25 01:08:23,371 - mmseg - INFO - Iter [650/5000]\tlr: 2.259e-05, eta: 1:00:37, time: 0.657, data_time: 0.050, memory: 9861, decode.loss_ce: 0.1704, decode.acc_seg: 95.0034, loss: 0.1704\n","2022-08-25 01:08:54,068 - mmseg - INFO - Iter [700/5000]\tlr: 2.405e-05, eta: 0:58:47, time: 0.614, data_time: 0.007, memory: 9861, decode.loss_ce: 0.1555, decode.acc_seg: 95.3961, loss: 0.1555\n","2022-08-25 01:09:24,789 - mmseg - INFO - Iter [750/5000]\tlr: 2.547e-05, eta: 0:57:08, time: 0.614, data_time: 0.007, memory: 9861, decode.loss_ce: 0.1299, decode.acc_seg: 96.0769, loss: 0.1299\n","2022-08-25 01:09:55,962 - mmseg - INFO - Iter [800/5000]\tlr: 2.685e-05, eta: 0:55:39, time: 0.623, data_time: 0.008, memory: 9861, decode.loss_ce: 0.1335, decode.acc_seg: 95.9012, loss: 0.1335\n","2022-08-25 01:10:26,602 - mmseg - INFO - Iter [850/5000]\tlr: 2.819e-05, eta: 0:54:15, time: 0.613, data_time: 0.007, memory: 9861, decode.loss_ce: 0.1139, decode.acc_seg: 96.4832, loss: 0.1139\n","2022-08-25 01:10:57,347 - mmseg - INFO - Iter [900/5000]\tlr: 2.949e-05, eta: 0:52:57, time: 0.615, data_time: 0.007, memory: 9861, decode.loss_ce: 0.1200, decode.acc_seg: 96.2066, loss: 0.1200\n","2022-08-25 01:11:30,372 - mmseg - INFO - Iter [950/5000]\tlr: 3.076e-05, eta: 0:51:54, time: 0.660, data_time: 0.049, memory: 9861, decode.loss_ce: 0.1152, decode.acc_seg: 96.2179, loss: 0.1152\n","2022-08-25 01:12:01,081 - mmseg - INFO - Exp name: config2.py\n","2022-08-25 01:12:01,082 - mmseg - INFO - Iter [1000/5000]\tlr: 3.198e-05, eta: 0:50:45, time: 0.614, data_time: 0.007, memory: 9861, decode.loss_ce: 0.1047, decode.acc_seg: 96.4840, loss: 0.1047\n","[>>] 280/280, 11.6 task/s, elapsed: 24s, ETA:     0s2022-08-25 01:12:25,170 - mmseg - INFO - per class results:\n","2022-08-25 01:12:25,171 - mmseg - INFO - \n","+----------------+-------+-------+\n","|     Class      |  IoU  |  Acc  |\n","+----------------+-------+-------+\n","|   background   | 96.18 | 97.73 |\n","|     kidney     | 77.16 | 90.25 |\n","|    prostate    | 70.91 | 93.34 |\n","| largeintestine | 74.98 |  87.1 |\n","|     spleen     | 66.36 | 78.48 |\n","|      lung      |  0.0  |  0.0  |\n","+----------------+-------+-------+\n","2022-08-25 01:12:25,171 - mmseg - INFO - Summary:\n","2022-08-25 01:12:25,171 - mmseg - INFO - \n","+-------+-------+-------+\n","|  aAcc |  mIoU |  mAcc |\n","+-------+-------+-------+\n","| 96.49 | 64.26 | 74.48 |\n","+-------+-------+-------+\n","2022-08-25 01:12:25,171 - mmseg - INFO - Exp name: config2.py\n","2022-08-25 01:12:25,172 - mmseg - INFO - Iter(val) [280]\taAcc: 0.9649, mIoU: 0.6426, mAcc: 0.7448, IoU.background: 0.9618, IoU.kidney: 0.7716, IoU.prostate: 0.7091, IoU.largeintestine: 0.7498, IoU.spleen: 0.6636, IoU.lung: 0.0000, Acc.background: 0.9773, Acc.kidney: 0.9025, Acc.prostate: 0.9334, Acc.largeintestine: 0.8710, Acc.spleen: 0.7848, Acc.lung: 0.0000\n","2022-08-25 01:12:55,989 - mmseg - INFO - Iter [1050/5000]\tlr: 3.316e-05, eta: 0:51:10, time: 1.098, data_time: 0.489, memory: 9861, decode.loss_ce: 0.1076, decode.acc_seg: 96.3729, loss: 0.1076\n","2022-08-25 01:13:26,871 - mmseg - INFO - Iter [1100/5000]\tlr: 3.430e-05, eta: 0:50:03, time: 0.618, data_time: 0.007, memory: 9861, decode.loss_ce: 0.1028, decode.acc_seg: 96.5315, loss: 0.1028\n","2022-08-25 01:13:57,657 - mmseg - INFO - Iter [1150/5000]\tlr: 3.540e-05, eta: 0:48:58, time: 0.616, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0992, decode.acc_seg: 96.6433, loss: 0.0992\n","2022-08-25 01:14:28,385 - mmseg - INFO - Iter [1200/5000]\tlr: 3.646e-05, eta: 0:47:57, time: 0.615, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0895, decode.acc_seg: 96.9116, loss: 0.0895\n","2022-08-25 01:14:59,598 - mmseg - INFO - Iter [1250/5000]\tlr: 3.748e-05, eta: 0:46:59, time: 0.624, data_time: 0.008, memory: 9861, decode.loss_ce: 0.0938, decode.acc_seg: 96.7203, loss: 0.0938\n","2022-08-25 01:15:32,726 - mmseg - INFO - Iter [1300/5000]\tlr: 3.846e-05, eta: 0:46:09, time: 0.663, data_time: 0.050, memory: 9861, decode.loss_ce: 0.0841, decode.acc_seg: 97.0929, loss: 0.0841\n","2022-08-25 01:16:03,467 - mmseg - INFO - Iter [1350/5000]\tlr: 3.940e-05, eta: 0:45:13, time: 0.615, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0863, decode.acc_seg: 97.0611, loss: 0.0863\n","2022-08-25 01:16:34,274 - mmseg - INFO - Iter [1400/5000]\tlr: 4.030e-05, eta: 0:44:20, time: 0.616, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0836, decode.acc_seg: 97.0444, loss: 0.0836\n","2022-08-25 01:17:05,517 - mmseg - INFO - Iter [1450/5000]\tlr: 4.116e-05, eta: 0:43:29, time: 0.625, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0923, decode.acc_seg: 96.7737, loss: 0.0923\n","2022-08-25 01:17:36,224 - mmseg - INFO - Iter [1500/5000]\tlr: 4.198e-05, eta: 0:42:38, time: 0.614, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0802, decode.acc_seg: 97.1121, loss: 0.0802\n","[>>] 280/280, 12.1 task/s, elapsed: 23s, ETA:     0s2022-08-25 01:17:59,355 - mmseg - INFO - per class results:\n","2022-08-25 01:17:59,356 - mmseg - INFO - \n","+----------------+-------+-------+\n","|     Class      |  IoU  |  Acc  |\n","+----------------+-------+-------+\n","|   background   | 96.47 | 98.12 |\n","|     kidney     | 79.99 | 88.39 |\n","|    prostate    | 73.18 | 91.09 |\n","| largeintestine | 77.47 |  87.4 |\n","|     spleen     | 63.95 | 77.52 |\n","|      lung      |  0.0  |  0.0  |\n","+----------------+-------+-------+\n","2022-08-25 01:17:59,356 - mmseg - INFO - Summary:\n","2022-08-25 01:17:59,356 - mmseg - INFO - \n","+-------+-------+-------+\n","|  aAcc |  mIoU |  mAcc |\n","+-------+-------+-------+\n","| 96.76 | 65.18 | 73.75 |\n","+-------+-------+-------+\n","2022-08-25 01:17:59,356 - mmseg - INFO - Iter(val) [280]\taAcc: 0.9676, mIoU: 0.6518, mAcc: 0.7375, IoU.background: 0.9647, IoU.kidney: 0.7999, IoU.prostate: 0.7318, IoU.largeintestine: 0.7747, IoU.spleen: 0.6395, IoU.lung: 0.0000, Acc.background: 0.9812, Acc.kidney: 0.8839, Acc.prostate: 0.9109, Acc.largeintestine: 0.8740, Acc.spleen: 0.7752, Acc.lung: 0.0000\n","2022-08-25 01:18:30,285 - mmseg - INFO - Iter [1550/5000]\tlr: 4.141e-05, eta: 0:42:40, time: 1.081, data_time: 0.469, memory: 9861, decode.loss_ce: 0.0749, decode.acc_seg: 97.2967, loss: 0.0749\n","2022-08-25 01:19:03,418 - mmseg - INFO - Iter [1600/5000]\tlr: 4.081e-05, eta: 0:41:55, time: 0.663, data_time: 0.050, memory: 9861, decode.loss_ce: 0.0702, decode.acc_seg: 97.5147, loss: 0.0702\n","2022-08-25 01:19:34,601 - mmseg - INFO - Iter [1650/5000]\tlr: 4.021e-05, eta: 0:41:06, time: 0.624, data_time: 0.008, memory: 9861, decode.loss_ce: 0.0735, decode.acc_seg: 97.3125, loss: 0.0735\n","2022-08-25 01:20:05,388 - mmseg - INFO - Iter [1700/5000]\tlr: 3.961e-05, eta: 0:40:17, time: 0.616, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0775, decode.acc_seg: 97.0907, loss: 0.0775\n","2022-08-25 01:20:36,184 - mmseg - INFO - Iter [1750/5000]\tlr: 3.901e-05, eta: 0:39:30, time: 0.616, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0607, decode.acc_seg: 97.8362, loss: 0.0607\n","2022-08-25 01:21:06,945 - mmseg - INFO - Iter [1800/5000]\tlr: 3.841e-05, eta: 0:38:43, time: 0.615, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0837, decode.acc_seg: 96.9282, loss: 0.0837\n","2022-08-25 01:21:37,687 - mmseg - INFO - Iter [1850/5000]\tlr: 3.781e-05, eta: 0:37:58, time: 0.615, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0691, decode.acc_seg: 97.4519, loss: 0.0691\n","2022-08-25 01:22:11,201 - mmseg - INFO - Iter [1900/5000]\tlr: 3.721e-05, eta: 0:37:17, time: 0.670, data_time: 0.052, memory: 9861, decode.loss_ce: 0.0689, decode.acc_seg: 97.4481, loss: 0.0689\n","2022-08-25 01:22:41,882 - mmseg - INFO - Iter [1950/5000]\tlr: 3.661e-05, eta: 0:36:33, time: 0.614, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0727, decode.acc_seg: 97.4093, loss: 0.0727\n","2022-08-25 01:23:12,668 - mmseg - INFO - Exp name: config2.py\n","2022-08-25 01:23:12,668 - mmseg - INFO - Iter [2000/5000]\tlr: 3.601e-05, eta: 0:35:49, time: 0.616, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0630, decode.acc_seg: 97.7472, loss: 0.0630\n","[>>] 280/280, 12.2 task/s, elapsed: 23s, ETA:     0s2022-08-25 01:23:35,716 - mmseg - INFO - per class results:\n","2022-08-25 01:23:35,717 - mmseg - INFO - \n","+----------------+-------+-------+\n","|     Class      |  IoU  |  Acc  |\n","+----------------+-------+-------+\n","|   background   | 96.71 | 98.02 |\n","|     kidney     | 83.75 | 90.23 |\n","|    prostate    |  73.5 | 95.01 |\n","| largeintestine | 78.98 | 91.31 |\n","|     spleen     | 70.82 | 79.52 |\n","|      lung      |  0.0  |  0.0  |\n","+----------------+-------+-------+\n","2022-08-25 01:23:35,717 - mmseg - INFO - Summary:\n","2022-08-25 01:23:35,717 - mmseg - INFO - \n","+-------+-------+-------+\n","|  aAcc |  mIoU |  mAcc |\n","+-------+-------+-------+\n","| 96.99 | 67.29 | 75.68 |\n","+-------+-------+-------+\n","2022-08-25 01:23:35,717 - mmseg - INFO - Exp name: config2.py\n","2022-08-25 01:23:35,718 - mmseg - INFO - Iter(val) [280]\taAcc: 0.9699, mIoU: 0.6729, mAcc: 0.7568, IoU.background: 0.9671, IoU.kidney: 0.8375, IoU.prostate: 0.7350, IoU.largeintestine: 0.7898, IoU.spleen: 0.7082, IoU.lung: 0.0000, Acc.background: 0.9802, Acc.kidney: 0.9023, Acc.prostate: 0.9501, Acc.largeintestine: 0.9131, Acc.spleen: 0.7952, Acc.lung: 0.0000\n","2022-08-25 01:24:07,038 - mmseg - INFO - Iter [2050/5000]\tlr: 3.541e-05, eta: 0:35:40, time: 1.087, data_time: 0.468, memory: 9861, decode.loss_ce: 0.0635, decode.acc_seg: 97.7206, loss: 0.0635\n","2022-08-25 01:24:38,106 - mmseg - INFO - Iter [2100/5000]\tlr: 3.481e-05, eta: 0:34:56, time: 0.621, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0614, decode.acc_seg: 97.6414, loss: 0.0614\n","2022-08-25 01:25:08,659 - mmseg - INFO - Iter [2150/5000]\tlr: 3.421e-05, eta: 0:34:13, time: 0.611, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0595, decode.acc_seg: 97.7959, loss: 0.0595\n","2022-08-25 01:25:41,564 - mmseg - INFO - Iter [2200/5000]\tlr: 3.361e-05, eta: 0:33:33, time: 0.658, data_time: 0.049, memory: 9861, decode.loss_ce: 0.0526, decode.acc_seg: 97.9942, loss: 0.0526\n","2022-08-25 01:26:12,384 - mmseg - INFO - Iter [2250/5000]\tlr: 3.301e-05, eta: 0:32:50, time: 0.616, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0540, decode.acc_seg: 97.9992, loss: 0.0540\n","2022-08-25 01:26:43,622 - mmseg - INFO - Iter [2300/5000]\tlr: 3.241e-05, eta: 0:32:09, time: 0.625, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0508, decode.acc_seg: 98.0900, loss: 0.0508\n","2022-08-25 01:27:14,353 - mmseg - INFO - Iter [2350/5000]\tlr: 3.181e-05, eta: 0:31:28, time: 0.615, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0504, decode.acc_seg: 98.0610, loss: 0.0504\n","2022-08-25 01:27:45,052 - mmseg - INFO - Iter [2400/5000]\tlr: 3.121e-05, eta: 0:30:47, time: 0.614, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0597, decode.acc_seg: 97.7774, loss: 0.0597\n","2022-08-25 01:28:15,692 - mmseg - INFO - Iter [2450/5000]\tlr: 3.061e-05, eta: 0:30:06, time: 0.613, data_time: 0.006, memory: 9861, decode.loss_ce: 0.0619, decode.acc_seg: 97.5202, loss: 0.0619\n","2022-08-25 01:28:46,568 - mmseg - INFO - Iter [2500/5000]\tlr: 3.001e-05, eta: 0:29:26, time: 0.618, data_time: 0.007, memory: 9861, decode.loss_ce: 0.0550, decode.acc_seg: 97.9576, loss: 0.0550\n","[>>] 280/280, 11.7 task/s, elapsed: 24s, ETA:     0s2022-08-25 01:29:10,505 - mmseg - INFO - per class results:\n","2022-08-25 01:29:10,506 - mmseg - INFO - \n","+----------------+-------+-------+\n","|     Class      |  IoU  |  Acc  |\n","+----------------+-------+-------+\n","|   background   | 96.79 | 98.58 |\n","|     kidney     | 83.81 | 90.82 |\n","|    prostate    | 71.61 | 83.03 |\n","| largeintestine | 79.38 | 86.46 |\n","|     spleen     | 70.59 | 86.41 |\n","|      lung      |  1.13 |  1.14 |\n","+----------------+-------+-------+\n","2022-08-25 01:29:10,506 - mmseg - INFO - Summary:\n","2022-08-25 01:29:10,506 - mmseg - INFO - \n","+-------+-------+-------+\n","|  aAcc |  mIoU |  mAcc |\n","+-------+-------+-------+\n","| 97.05 | 67.22 | 74.41 |\n","+-------+-------+-------+\n","2022-08-25 01:29:10,507 - mmseg - INFO - Iter(val) [280]\taAcc: 0.9705, mIoU: 0.6722, mAcc: 0.7441, IoU.background: 0.9679, IoU.kidney: 0.8381, IoU.prostate: 0.7161, IoU.largeintestine: 0.7938, IoU.spleen: 0.7059, IoU.lung: 0.0113, Acc.background: 0.9858, Acc.kidney: 0.9082, Acc.prostate: 0.8303, Acc.largeintestine: 0.8646, Acc.spleen: 0.8641, Acc.lung: 0.0114\n","2022-08-25 01:29:43,947 - mmseg - INFO - Iter [2550/5000]\tlr: 2.941e-05, eta: 0:29:12, time: 1.148, data_time: 0.529, memory: 9861, decode.loss_ce: 0.0512, decode.acc_seg: 98.0324, loss: 0.0512\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"gbDfxudYXTTf"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"train.ipynb","provenance":[],"authorship_tag":"ABX9TyOMNejOUMjF9alKWr/Ix1Vn"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}